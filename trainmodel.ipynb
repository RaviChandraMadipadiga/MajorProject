{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "frKv4sZK9S0D"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hii\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import sys\n",
    "sys.path.append('F:/Mjrpjct/Speech-Accent-Recognition-master/src')\n",
    "import getsplit\n",
    "print(\"Hii\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G7fl48V79Vm8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import utils\n",
    "import accuracy\n",
    "import multiprocessing\n",
    "import librosa\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Flatten\n",
    "from keras.layers.convolutional import MaxPooling2D, Conv2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import EarlyStopping, TensorBoard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CATS7WRX9YVJ"
   },
   "outputs": [],
   "source": [
    "DEBUG = True\n",
    "SILENCE_THRESHOLD = .01\n",
    "RATE = 24000\n",
    "N_MFCC = 13\n",
    "COL_SIZE = 30\n",
    "EPOCHS = 15 #35#250\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I0kdH0f19jtP"
   },
   "outputs": [],
   "source": [
    "def to_categorical(y):\n",
    "    '''\n",
    "    Converts list of languages into a binary class matrix\n",
    "    :param y (list): list of languages\n",
    "    :return (numpy array): binary class matrix\n",
    "    '''\n",
    "    lang_dict = {}\n",
    "    for index,language in enumerate(set(y)):\n",
    "        lang_dict[language] = index\n",
    "    y = list(map(lambda x: lang_dict[x],y))\n",
    "    return utils.to_categorical(y, len(lang_dict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zDSgaLVR9575"
   },
   "outputs": [],
   "source": [
    "def save_model(model, model_filename):\n",
    "    '''\n",
    "    Save model to file\n",
    "    :param model: Trained model to be saved\n",
    "    :param model_filename: Filename\n",
    "    :return: None\n",
    "    '''\n",
    "    model.save('models/{}.h5'.format(model_filename))  # creates a HDF5 file 'my_model.h5'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JDIWZ15Z9mKo"
   },
   "outputs": [],
   "source": [
    "def get_wav(language_num):\n",
    "    '''\n",
    "    Load wav file from disk and down-samples to RATE\n",
    "    :param language_num (list): list of file names\n",
    "    :return (numpy array): Down-sampled wav file\n",
    "    '''\n",
    "\n",
    "    y, sr = librosa.load('F:/Mjrpjct/Speech-Accent-Recognition-master/src/audio/{}.wav'.format(language_num))\n",
    "    return(librosa.core.resample(y=y,orig_sr=sr,target_sr=RATE, scale=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AOysRMug9oWM"
   },
   "outputs": [],
   "source": [
    "def to_mfcc(wav):\n",
    "    '''\n",
    "    Converts wav file to Mel Frequency Ceptral Coefficients\n",
    "    :param wav (numpy array): Wav form\n",
    "    :return (2d numpy array: MFCC\n",
    "    '''\n",
    "    return(librosa.feature.mfcc(y=wav, sr=RATE, n_mfcc=N_MFCC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C5XdmWnT9q5g"
   },
   "outputs": [],
   "source": [
    "def remove_silence(wav, thresh=0.04, chunk=5000):\n",
    "    '''\n",
    "    Searches wav form for segments of silence. If wav form values are lower than 'thresh' for 'chunk' samples, the values will be removed\n",
    "    :param wav (np array): Wav array to be filtered\n",
    "    :return (np array): Wav array with silence removed\n",
    "    '''\n",
    "\n",
    "    tf_list = []\n",
    "    for x in range(len(wav) / chunk):\n",
    "        if (np.any(wav[chunk * x:chunk * (x + 1)] >= thresh) or np.any(wav[chunk * x:chunk * (x + 1)] <= -thresh)):\n",
    "            tf_list.extend([True] * chunk)\n",
    "        else:\n",
    "            tf_list.extend([False] * chunk)\n",
    "\n",
    "    tf_list.extend((len(wav) - len(tf_list)) * [False])\n",
    "    return(wav[tf_list])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iWk_Wjuv9tis"
   },
   "outputs": [],
   "source": [
    "def normalize_mfcc(mfcc):\n",
    "    '''\n",
    "    Normalize mfcc\n",
    "    :param mfcc:\n",
    "    :return:\n",
    "    '''\n",
    "    mms = MinMaxScaler()\n",
    "    return(mms.fit_transform(np.abs(mfcc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ReHYITc79vsz"
   },
   "outputs": [],
   "source": [
    "def make_segments(mfccs,labels):\n",
    "    '''\n",
    "    Makes segments of mfccs and attaches them to the labels\n",
    "    :param mfccs: list of mfccs\n",
    "    :param labels: list of labels\n",
    "    :return (tuple): Segments with labels\n",
    "    '''\n",
    "    segments = []\n",
    "    seg_labels = []\n",
    "    for mfcc,label in zip(mfccs,labels):\n",
    "        for start in range(0, int(mfcc.shape[1] / COL_SIZE)):\n",
    "            segments.append(mfcc[:, start * COL_SIZE:(start + 1) * COL_SIZE])\n",
    "            seg_labels.append(label)\n",
    "    return(segments, seg_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zSO8THEC9yls"
   },
   "outputs": [],
   "source": [
    "def segment_one(mfcc):\n",
    "    '''\n",
    "    Creates segments from on mfcc image. If last segments is not long enough to be length of columns divided by COL_SIZE\n",
    "    :param mfcc (numpy array): MFCC array\n",
    "    :return (numpy array): Segmented MFCC array\n",
    "    '''\n",
    "    segments = []\n",
    "    for start in range(0, int(mfcc.shape[1] / COL_SIZE)):\n",
    "        segments.append(mfcc[:, start * COL_SIZE:(start + 1) * COL_SIZE])\n",
    "    return(np.array(segments))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SzBnityZ92A7"
   },
   "outputs": [],
   "source": [
    "def create_segmented_mfccs(X_train):\n",
    "    '''\n",
    "    Creates segmented MFCCs from X_train\n",
    "    :param X_train: list of MFCCs\n",
    "    :return: segmented mfccs\n",
    "    '''\n",
    "    segmented_mfccs = []\n",
    "    for mfcc in X_train:\n",
    "        segmented_mfccs.append(segment_one(mfcc))\n",
    "    return(segmented_mfccs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "FgVSfi2gVcYv",
    "outputId": "56a0d8f9-2cf4-48b2-85a5-e7178ff80b34"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'english\\n': 508, 'spanish\\n': 181, 'arabic\\n': 155, 'mandarin\\n': 121, 'russian\\n': 68, 'french\\n': 67})\n",
      "Counter({'english\\n': 137, 'spanish\\n': 46, 'arabic\\n': 38, 'mandarin\\n': 29, 'french\\n': 13, 'russian\\n': 13})\n",
      "Entering main\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    '''\n",
    "        Console command example:\n",
    "        python trainmodel.py bio_metadata.csv model50\n",
    "        '''\n",
    "\n",
    "    # Load arguments\n",
    "    # print(sys.argv)\n",
    "    file_name = 'F:/Mjrpjct/Speech-Accent-Recognition-master/src/bio_metadata.csv'\n",
    "    model_filename = 'model5'\n",
    "\n",
    "    # Load metadata\n",
    "    df = pd.read_csv(file_name)\n",
    "\n",
    "\n",
    "    # Filter metadata to retrieve only files desired\n",
    "    filtered_df = getsplit.filter_df(df)\n",
    "\n",
    "    # filtered_df = filter_df(df)\n",
    "\n",
    "    # print(filtered_df)\n",
    "\n",
    "    # print(\"filterd df is empty {}\".format(filtered_df))\n",
    "\n",
    "    # Train test split\n",
    "    X_train, X_test, y_train, y_test = getsplit.split_people(filtered_df)\n",
    "\n",
    "    # Get statistics\n",
    "    train_count = Counter(y_train)\n",
    "    test_count = Counter(y_test)\n",
    "    print(train_count)\n",
    "    print(test_count)\n",
    "    print(\"Entering main\")\n",
    "\n",
    "    # import ipdb;\n",
    "    # ipdb.set_trace()\n",
    "\n",
    "\n",
    "    acc_to_beat = test_count.most_common(1)[0][1] / float(np.sum(list(test_count.values())))\n",
    "\n",
    "    # To categorical\n",
    "    y_train = to_categorical(y_train)\n",
    "    y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "YYKsPGapxlMI",
    "outputId": "83dccc59-acef-46b8-8afb-80772b1c6fe2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading wav files....\n"
     ]
    }
   ],
   "source": [
    "    # Get resampled wav files using multiprocessing\n",
    "    if DEBUG:\n",
    "        print('Loading wav files....')\n",
    "    pool = multiprocessing.Pool(processes=multiprocessing.cpu_count())\n",
    "    X_train = pool.map(get_wav, X_train)\n",
    "    X_test = pool.map(get_wav, X_test)\n",
    "    print(\"Loading Finished\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5uFN56rTxqIZ"
   },
   "outputs": [],
   "source": [
    "# Convert to MFCC\n",
    "    if DEBUG:\n",
    "        print('Converting to MFCC....')\n",
    "    X_train = pool.map(to_mfcc, X_train)\n",
    "    X_test = pool.map(to_mfcc, X_test)\n",
    "\n",
    "    # Create segments from MFCCs\n",
    "    X_train, y_train = make_segments(X_train, y_train)\n",
    "    X_validation, y_validation = make_segments(X_test, y_test)\n",
    "    print(\"Xtrain Done\")\n",
    "    X_train, _, y_train, _ = train_test_split(X_train, y_train, test_size=0.4)\n",
    "    \n",
    "    #Training Model\n",
    "    X_train = np.array(X_train)\n",
    "    y_train = np.array(y_train)\n",
    "    X_validation = np.array(X_validation)\n",
    "    y_validation = np.array(y_validation)\n",
    "    print(\"Data Converted to arrays\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gNZDQhdM93yW"
   },
   "outputs": [],
   "source": [
    "#def train_model(X_train,y_train,X_validation,y_validation, batch_size=64): #64\n",
    "    '''\n",
    "    Trains 2D convolutional neural network\n",
    "    :param X_train: Numpy array of mfccs\n",
    "    :param y_train: Binary matrix based on labels\n",
    "    :return: Trained model\n",
    "    '''\n",
    "\n",
    "    # Get row, column, and class sizes\n",
    "    rows = X_train[0].shape[0]\n",
    "    cols = X_train[0].shape[1]\n",
    "    val_rows = X_validation[0].shape[0]\n",
    "    val_cols = X_validation[0].shape[1]\n",
    "    num_classes = 6\n",
    "    print(num_classes)\n",
    "    # input image dimensions to feed into 2D ConvNet Input layer\n",
    "    input_shape = (rows, cols, 1)\n",
    "    X_train = X_train.reshape(X_train.shape[0], rows, cols, 1 )\n",
    "    X_validation = X_validation.reshape(X_validation.shape[0],val_rows,val_cols,1)\n",
    "\n",
    "\n",
    "    print('X_train shape:', X_train.shape)\n",
    "    print(X_train.shape[0], 'training samples')\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(32, kernel_size=(3,3), activation='relu',\n",
    "                     data_format=\"channels_last\",\n",
    "                     input_shape=input_shape))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(64,kernel_size=(3,3), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropoout(0.1))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # Stops training if accuracy does not change at least 0.005 over 10 epochs\n",
    "    es = EarlyStopping(monitor='acc', min_delta=.005, patience=10, verbose=1, mode='auto')\n",
    "\n",
    "    # Creates log file for graphical interpretation using TensorBoard\n",
    "    tb = TensorBoard(log_dir='logs', histogram_freq=0, batch_size=32, write_graph=True, write_grads=True,\n",
    "                     write_images=True, embeddings_freq=0, embeddings_layer_names=None,\n",
    "                     embeddings_metadata=None)\n",
    "\n",
    "    # Image shifting\n",
    "    datagen = ImageDataGenerator(width_shift_range=0.05)\n",
    "\n",
    "    # Fit model using ImageDataGenerator\n",
    "    history = model.fit_generator(datagen.flow(X_train, y_train, batch_size=batch_size),\n",
    "                        steps_per_epoch=len(X_train) / 32\n",
    "                        , epochs=EPOCHS,\n",
    "                        callbacks=[es,tb], validation_data=(X_validation,y_validation))\n",
    "    loss_train = history.history['train_loss']\n",
    "    loss_val = history.history['val_loss']\n",
    "    epochs = range(1,35)\n",
    "    plt.plot(epochs, loss_train, 'g', label='Training loss')\n",
    "    plt.plot(epochs, loss_val, 'b', label='validation loss')\n",
    "    plt.title('Training and Validation loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    #return (model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Make predictions on full X_test MFCCs\n",
    "    y_predicted = accuracy.predict_class_all(create_segmented_mfccs(X_test), model)\n",
    "    print(\"Model Training Finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-4w8AJAWyC9P"
   },
   "outputs": [],
   "source": [
    "# Print statistics\n",
    "    print('Training samples:', train_count)\n",
    "    print('Testing samples:', test_count)\n",
    "    print('Accuracy to beat:', acc_to_beat)\n",
    "    print('Confusion matrix of total samples:\\n', np.sum(accuracy.confusion_matrix(y_predicted, y_test),axis=1))\n",
    "    print('Confusion matrix:\\n',accuracy.confusion_matrix(y_predicted, y_test))\n",
    "    print('Accuracy:', accuracy.get_accuracy(y_predicted,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q3F3Vf_wyH8S"
   },
   "outputs": [],
   "source": [
    "# Save model\n",
    "    save_model(model, model_filename)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "trainmodel.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
